# Deep Learning on MCU


## Website

- https://www.tinyml.org/
- Tiny machine learning is broadly defined as a fast growing field of machine learning technologies and applications including hardware, algorithms and software capable of performing on-device sensor data analytics at extremely low power, typically in the mW range and below, and hence enabling a variety of always-on use-cases and targeting battery operated devices.
- https://github.com/gigwegbe/tinyml-papers-and-projects


## Paper

- 2016-[EIE: Efficient Inference Engine on Compressed Deep Neural Network](https://arxiv.org/abs/1602.01528)-2896
- 2019-[EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://arxiv.org/abs/1905.11946)-15404
- 2020-[ATCN: Resource-Efficient Processing of Time Series on Edge](https://arxiv.org/abs/2011.05260)-2 | [code](https://github.com/TeCSAR-UNCC/ATCN)
- 2020-[Methodology for Efficient CNN Architectures in Profiling Attacks â€“ Extended Version](https://tches.iacr.org/index.php/TCHES/article/view/8391)-178
- 2020-[MCUNet: Tiny Deep Learning on IoT Devices](https://hanlab.mit.edu/projects/mcunetv1)-306 | [code](https://github.com/mit-han-lab/mcunet)
- 2021-[Network Augmentation for Tiny Deep Learning](https://arxiv.org/abs/2110.08890)-14
- 2021-[MCUNetV2: Memory-Efficient Patch-based Inference for Tiny Deep Learning](https://arxiv.org/abs/2110.15352)-59 | [code](https://github.com/mit-han-lab/mcunet)
- 2021-[Network Augmentation for Tiny Deep Learning](https://arxiv.org/abs/2110.08890)-14
- 2021-[Quantization and Deployment of Deep Neural Networks on Microcontrollers](https://www.mdpi.com/1424-8220/21/9/2984)-88
- 2021-[TinyML Platforms Benchmarking](https://arxiv.org/pdf/2112.01319.pdf)-17
- 2021-[Resource-Efficient Deep Learning: A Survey on Model-, Arithmetic-, and Implementation-Level Techniques](https://arxiv.org/abs/2112.15131)-9
- 2022-[A Survey on Efficient Convolutional Neural Networks and Hardware Acceleration](https://www.mdpi.com/2079-9292/11/6/945)-68
- 2022-[On-Device Training Under 256KB Memory](https://arxiv.org/abs/2206.15472)-58
- 2022-[SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models](https://arxiv.org/abs/2211.10438)-64 | [code](https://github.com/mit-han-lab/smoothquant)
- 2022-[Efficient CNN Architecture Design Guided by Visualization](https://arxiv.org/abs/2207.10318)-3
- 2022-[MVP- An Efficient CNN Accelerator with Matrix, Vector, and Processing-Near-Memory Units](https://dl.acm.org/doi/10.1145/3497745)-2
- 2022-[A novel framework for deployment of CNN models using post-training quantization on microcontroller](https://www.sciencedirect.com/science/article/abs/pii/S0141933122001715)-4

## Framework

- [EXECUTORCH-Pytorch Edge](https://pytorch.org/executorch-overview)
- [Glow](https://github.com/pytorch/glow)
- [Comparison of TinyML Inference Framework](https://github.com/sipeed/TinyMaix/blob/main/tinyml_intro.md#comparison-of-tinyml-inference-framework)
- [tinyengine](https://github.com/mit-han-lab/tinyengine)
- [TinyMaix](https://github.com/sipeed/TinyMaix)
- [Neural Network on Microcontroller (NNoM)](https://github.com/majianjia/nnom)
- [CMSIS NN](https://www.keil.com/pack/doc/CMSIS/NN/html/index.html)
- [tflite-micro](https://github.com/tensorflow/tflite-micro)
- [X-CUBE-AI](https://www.st.com/en/embedded-software/x-cube-ai.html) : an STM32Cube Expansion Package, which is part of the STM32Cube
- [uTensor](https://github.com/uTensor/uTensor) : TinyML AI inference library

## Tutorial

- [TinyML is bringing neural networks to microcontrollers](https://bdtechtalks.com/2022/01/17/mcunetv2-tinyml-deep-learning-microcontrollers/)

### model compression

- https://github.com/cedrickchee/awesome-ml-model-compression
- [PyTortch Pruning](https://pytorch.org/tutorials/intermediate/pruning_tutorial.html)
- [PyTorch Quatization](https://pytorch.org/docs/stable/quantization.html)
- [4 Popular Model Compression Techniques Explained](https://xailient.com/blog/4-popular-model-compression-techniques-explained/) : Pruning | Quantization | Knowledge distillation | Low-rank factorization
- [An Overview of Model Compression Techniques for Deep Learning in Space](https://medium.com/gsi-technology/an-overview-of-model-compression-techniques-for-deep-learning-in-space-3fd8d4ce84e5)

### MCU

- [Glow Compiler Optimizes Neural Networks for Low Power NXP MCUs](https://medium.com/pytorch/glow-compiler-optimizes-neural-networks-for-low-power-nxp-mcus-e095abe14942)

## Book 

- [Efficient Deep Learning Book](https://efficientdlbook.com/)
- [AI at the Edge](https://www.oreilly.com/library/view/ai-at-the/9781098120191/)
- [Introduction to TinyML](https://www.thetinymlbook.com/)

## Class

- [TinyML and Efficient Deep Learning Computing](https://hanlab.mit.edu/courses/2023-fall-65940)
